# -*- coding: utf-8 -*-
"""Titanic project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1i5uhrxr_bvP6GzQXl4dKJvJDkGYS4Je2
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

train=pd.read_csv('train.csv')
test=pd.read_csv('test.csv')

train.head(10)

sns.heatmap(train.isnull().sum().to_frame(),annot=True)

sns.heatmap(test.isnull().sum().to_frame(),annot=True)

sns.set_style('whitegrid')
sns.countplot(x='Survived',data=train)

sns.countplot(x='Survived',data=train,hue='Sex',palette='RdBu_r')

sns.countplot(x='Survived',data=train,hue='Pclass',palette='rainbow')

sns.distplot(train['Age'].dropna(),kde=False,color='green',bins=20)

sns.countplot(x='SibSp',data=train)

sns.distplot(train['Fare'].dropna(),kde=False,color='blue',bins=20)

sns.boxplot(x='Pclass',y='Age',data=train,palette='winter')

train.loc[train['Age'].isna(),'Age'] =train.loc[train['Age'].notna(),'Age'].median()
train.drop('Cabin',axis=1,inplace=True)

sns.heatmap(train.isnull(),yticklabels=False,cbar=False,cmap='viridis')

pd.get_dummies(train['Embarked'],drop_first=True).head()
sex=pd.get_dummies(train['Sex'],drop_first=True)
embark=pd.get_dummies(train['Embarked'],drop_first=True)

train.drop(['Sex','Embarked','Name','Ticket'],axis=1,inplace=True)

train=pd.concat([train,sex,embark],axis=1)

train.head()

train.drop('Survived',axis=1).head()

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test =train_test_split(train.drop('Survived',axis=1),
                                               train['Survived'], test_size=0.30,
                                               random_state=1)

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
x_train = sc.fit_transform(x_train)
x_test = sc.transform(x_test)

#Create a function within many Machine Learning Models
def models(X_train,Y_train):

  #Using DecisionTreeClassifier of tree class to use Decision Tree Algorithm
  from sklearn.tree import DecisionTreeClassifier
  tree = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)
  tree.fit(X_train, Y_train)

  #Using RandomForestClassifier method of ensemble class to use Random Forest Classification algorithm
  from sklearn.ensemble import RandomForestClassifier
  forest = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)
  forest.fit(X_train, Y_train)
  
  #print model accuracy on the training data.
  
  print('[0]Decision Tree Classifier Training Accuracy:', tree.score(X_train, Y_train))
  print('[1]Random Forest Classifier Training Accuracy:', forest.score(X_train, Y_train))
  
  return  tree, forest

#Get and train all of the models
model = models(x_train,y_train)

from sklearn.metrics import confusion_matrix 
for i in range(len(model)):
   cm = confusion_matrix(y_test, model[i].predict(x_test)) 
   #extracting TN, FP, FN, TP
   TN, FP, FN, TP = confusion_matrix(y_test, model[i].predict(x_test)).ravel()
   print(cm)
   print('Model[{}] Testing Accuracy = "{} !"'.format(i,  (TP + TN) / (TP + TN + FN + FP)))
   print()# Print a new line

#Print Prediction of Random Forest Classifier model
pred = model[1].predict(x_test)
print(pred)

#Print a space
print()

#Print the actual values
print(y_test)

my_survival = [[1,3,22.0,1,0,7.2500,1,0,1]]
pred = model[0].predict(my_survival)
print(pred)

if pred == 0:
  print("Oh no! You didn't make it")
else:
  print('Nice! You survived')

my_survival = [[3,3,26.0,0,0,7.9250,0,0,1]]
pred = model[0].predict(my_survival)
print(pred)

if pred == 0:
  print("Oh no! You didn't make it")
else:
  print('Nice! You survived')







